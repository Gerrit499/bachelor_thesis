{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a49c5857",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch version 2.6.0+cu126 available.\n"
     ]
    }
   ],
   "source": [
    "# 1 Setup\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\".\"))\n",
    "from model_560m import generate_translation\n",
    "\n",
    "import comet\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40f7864b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples in zho-eng: 997\n",
      "Number of examples in eng-zho: 997\n",
      "Number of examples in fra-eng: 997\n",
      "Number of examples in eng-fra: 997\n",
      "Number of examples in nld-eng: 997\n",
      "Number of examples in eng-nld: 997\n",
      "Number of examples in khk-eng: 997\n",
      "Number of examples in eng-khk: 997\n"
     ]
    }
   ],
   "source": [
    "# 2 Data\n",
    "dataset = load_dataset(\"Muennighoff/flores200\", \"all\", revision=\"refs/pr/7\", trust_remote_code=True)\n",
    "dev_set = dataset[\"dev\"]\n",
    "lang_pairs = {\n",
    "    \"zho-eng\": dev_set.filter(lambda x: x[\"sentence_zho_Hans\"] and x[\"sentence_eng_Latn\"]),\n",
    "    \"eng-zho\": dev_set.filter(lambda x: x[\"sentence_eng_Latn\"] and x[\"sentence_zho_Hans\"]),\n",
    "    \"fra-eng\": dev_set.filter(lambda x: x[\"sentence_fra_Latn\"] and x[\"sentence_eng_Latn\"]),\n",
    "    \"eng-fra\": dev_set.filter(lambda x: x[\"sentence_eng_Latn\"] and x[\"sentence_fra_Latn\"]),\n",
    "    \"nld-eng\": dev_set.filter(lambda x: x[\"sentence_nld_Latn\"] and x[\"sentence_eng_Latn\"]),\n",
    "    \"eng-nld\": dev_set.filter(lambda x: x[\"sentence_eng_Latn\"] and x[\"sentence_nld_Latn\"]),\n",
    "    \"khk-eng\": dev_set.filter(lambda x: x[\"sentence_khk_Cyrl\"] and x[\"sentence_eng_Latn\"]),\n",
    "    \"eng-khk\": dev_set.filter(lambda x: x[\"sentence_eng_Latn\"] and x[\"sentence_khk_Cyrl\"]),\n",
    "}\n",
    "print(\"Number of examples in zho-eng:\", len(lang_pairs[\"zho-eng\"]))\n",
    "print(\"Number of examples in eng-zho:\", len(lang_pairs[\"eng-zho\"]))\n",
    "print(\"Number of examples in fra-eng:\", len(lang_pairs[\"fra-eng\"]))\n",
    "print(\"Number of examples in eng-fra:\", len(lang_pairs[\"eng-fra\"]))\n",
    "print(\"Number of examples in nld-eng:\", len(lang_pairs[\"nld-eng\"]))\n",
    "print(\"Number of examples in eng-nld:\", len(lang_pairs[\"eng-nld\"]))\n",
    "print(\"Number of examples in khk-eng:\", len(lang_pairs[\"khk-eng\"]))\n",
    "print(\"Number of examples in eng-khk:\", len(lang_pairs[\"eng-khk\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94e85a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gerri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\gerri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# 3 BLEU and METEOR\n",
    "import sacrebleu\n",
    "\n",
    "def compute_bleu(predictions, references):\n",
    "    if isinstance(predictions, str):\n",
    "        predictions = [predictions]\n",
    "    if isinstance(references[0], str):\n",
    "        references = [[ref] for ref in references]\n",
    "\n",
    "    scores = []\n",
    "    for pred, ref in zip(predictions, references):\n",
    "        score = sacrebleu.sentence_bleu(pred, ref).score\n",
    "        scores.append(score)\n",
    "    return scores\n",
    "\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"punkt_tab\")\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "\n",
    "def compute_meteor(predictions, references):\n",
    "    if isinstance(predictions, str):\n",
    "        predictions = [predictions]\n",
    "    if isinstance(references, str):\n",
    "        references = [references]\n",
    "\n",
    "    scores = []\n",
    "    for pred, ref in zip(predictions, references):\n",
    "        score = meteor_score([word_tokenize(ref)], word_tokenize(pred))\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df5d02a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95c83afe12574469a8293d30c85c5821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.5.1. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\gerri\\.cache\\huggingface\\hub\\models--Unbabel--wmt22-comet-da\\snapshots\\2760a223ac957f30acfb18c8aa649b01cf1d75f2\\checkpoints\\model.ckpt`\n",
      "Encoder model frozen.\n",
      "C:\\Users\\gerri\\AppData\\Roaming\\Python\\Python312\\site-packages\\pytorch_lightning\\core\\saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ca8def8cfce4725b05c45b28f52544e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.8.2 to v2.5.1. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\gerri\\.cache\\huggingface\\hub\\models--Unbabel--wmt22-cometkiwi-da\\snapshots\\1ad785194e391eebc6c53e2d0776cada8f83179a\\checkpoints\\model.ckpt`\n",
      "Encoder model frozen.\n"
     ]
    }
   ],
   "source": [
    "# 4 COMET\n",
    "from comet import download_model, load_from_checkpoint\n",
    "\n",
    "# Reference-based COMET\n",
    "comet_ref_model_path = download_model(\"Unbabel/wmt22-comet-da\")\n",
    "comet_ref_model = load_from_checkpoint(comet_ref_model_path)\n",
    "\n",
    "# Reference-free COMET\n",
    "cometkiwi_model_path = download_model(\"Unbabel/wmt22-cometkiwi-da\")\n",
    "cometkiwi_model = load_from_checkpoint(cometkiwi_model_path)\n",
    "\n",
    "\n",
    "# Safety check\n",
    "if \"comet_ref_model\" not in globals():\n",
    "    comet_ref_model_path = download_model(\"Unbabel/wmt22-comet-da\")\n",
    "    comet_ref_model = load_from_checkpoint(comet_ref_model_path)\n",
    "\n",
    "if \"cometkiwi_model\" not in globals():\n",
    "    cometkiwi_model_path = download_model(\"Unbabel/wmt22-cometkiwi-da\")\n",
    "    cometkiwi_model = load_from_checkpoint(cometkiwi_model_path)\n",
    "\n",
    "# Compute COMET scores\n",
    "def compute_comet_ref(srcs, mts, refs):\n",
    "    try:\n",
    "        data = [{\"src\": s, \"mt\": m, \"ref\": r} for s, m, r in zip(srcs, mts, refs)]\n",
    "        score = comet_ref_model.predict(data, gpus=1 if torch.cuda.is_available() else 0)\n",
    "        return score.scores\n",
    "    except Exception as e:\n",
    "        print(f\"[COMET-REF ERROR] {e}\")\n",
    "        return [float(\"nan\")] * len(srcs)\n",
    "\n",
    "def compute_cometkiwi(srcs, mts):\n",
    "    try:\n",
    "        data = [{\"src\": s, \"mt\": m} for s, m in zip(srcs, mts)]\n",
    "        score = cometkiwi_model.predict(data, gpus=1 if torch.cuda.is_available() else 0)\n",
    "        return score.scores\n",
    "    except Exception as e:\n",
    "        print(f\"[COMET-KIWI ERROR] {e}\")\n",
    "        return [float(\"nan\")] * len(srcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cac68e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 Results + getting translations\n",
    "def get_results_batched(examples, source_field, target_field, prompt_template, direction, results_list):\n",
    "    strategies = [\"greedy\"]\n",
    "\n",
    "    for strategy in strategies:\n",
    "        print(f\"\\n[Strategy: {strategy}]\")\n",
    "\n",
    "        prompts = []\n",
    "        sources = []\n",
    "        references = []\n",
    "\n",
    "        # Generate prompts and collect source/reference\n",
    "        for ex in examples:\n",
    "            source = ex[source_field]\n",
    "            reference = ex[target_field]\n",
    "            prompt = prompt_template.format(source=source)\n",
    "\n",
    "            prompts.append(prompt)\n",
    "            sources.append(source)\n",
    "            references.append(reference)\n",
    "\n",
    "        # Generate translations in batch + log probs + perplexities\n",
    "        translations = []\n",
    "        log_probs = []\n",
    "        perplexities = []\n",
    "        for prompt in tqdm(prompts, desc=f\"Translating ({strategy})\"):\n",
    "            try:\n",
    "                translation, log_prob, ppl = generate_translation(prompt, strategy)\n",
    "                translations.append(translation)\n",
    "                log_probs.append(log_prob)\n",
    "                perplexities.append(ppl)\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] Strategy {strategy}: {e}\")\n",
    "                translations.append(\"\")\n",
    "                log_probs.append(float(\"nan\"))\n",
    "                perplexities.append(float(\"nan\"))\n",
    "\n",
    "        # Compute BLEU and METEOR in batch\n",
    "        bleu_scores = compute_bleu(translations, references)\n",
    "        meteor_scores = compute_meteor(translations, references)\n",
    "\n",
    "        # Compute COMET scores (aligned)\n",
    "        valid_indices = [i for i, t in enumerate(translations) if t.strip()]\n",
    "        comet_refs = [float(\"nan\")] * len(translations)\n",
    "        comet_wmt = [float(\"nan\")] * len(translations)\n",
    "\n",
    "        try:\n",
    "            valid_sources = [sources[i] for i in valid_indices]\n",
    "            valid_refs = [references[i] for i in valid_indices]\n",
    "            valid_trans = [translations[i] for i in valid_indices]\n",
    "\n",
    "            comet_ref_scores = compute_comet_ref(valid_sources, valid_trans, valid_refs)\n",
    "            comet_wmt_scores = compute_cometkiwi(valid_sources, valid_trans)\n",
    "\n",
    "            for j, idx in enumerate(valid_indices):\n",
    "                comet_refs[idx] = comet_ref_scores[j]\n",
    "                comet_wmt[idx] = comet_wmt_scores[j]\n",
    "        except Exception as e:\n",
    "            print(f\"[COMET ERROR] {e}\")\n",
    "\n",
    "        # Store results\n",
    "        for i in range(len(translations)):\n",
    "            results_list.append({\n",
    "                \"source\": sources[i],\n",
    "                \"reference\": references[i],\n",
    "                \"strategy\": strategy,\n",
    "                \"translation\": translations[i],\n",
    "                \"total_log_probs\": log_probs[i],\n",
    "                \"perplexity\": perplexities[i],\n",
    "                \"bleu\": bleu_scores[i],\n",
    "                \"meteor\": meteor_scores[i],\n",
    "                \"comet_ref\": comet_refs[i],\n",
    "                \"comet_wmt22\": comet_wmt[i]\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70a62077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Destination results\n",
    "output_dir = \"csv_results_560\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667337a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Strategy: greedy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating (greedy): 100%|██████████| 997/997 [23:20<00:00,  1.40s/it]\n",
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Predicting DataLoader 0: 100%|██████████| 63/63 [00:16<00:00,  3.72it/s]\n",
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Predicting DataLoader 0: 100%|██████████| 63/63 [00:07<00:00,  8.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Strategy: greedy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating (greedy): 100%|██████████| 997/997 [15:53<00:00,  1.05it/s]\n",
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Predicting DataLoader 0: 100%|██████████| 63/63 [00:12<00:00,  4.89it/s]\n",
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Predicting DataLoader 0: 100%|██████████| 63/63 [00:08<00:00,  7.65it/s]\n"
     ]
    }
   ],
   "source": [
    "# zho to eng\n",
    "results_to_eng = []\n",
    "source_field = \"sentence_zho_Hans\"\n",
    "target_field = \"sentence_eng_Latn\"\n",
    "prompt_zh2en = \"\"\"Task: Translate the following Chinese text to English.\n",
    "\n",
    "Chinese text: {source}\n",
    "\n",
    "English translation:\"\"\".strip()\n",
    "\n",
    "get_results_batched(\n",
    "    examples=lang_pairs[\"zho-eng\"].select(range(len(lang_pairs[\"zho-eng\"]))),\n",
    "    source_field=source_field,\n",
    "    target_field=target_field,\n",
    "    prompt_template=prompt_zh2en,\n",
    "    direction=\"zho-eng\",\n",
    "    results_list=results_to_eng\n",
    ")\n",
    "\n",
    "# eng tp zho\n",
    "results_to_zho = []\n",
    "source_field = \"sentence_eng_Latn\"\n",
    "target_field = \"sentence_zho_Hans\"\n",
    "prompt_en2zh = \"\"\"Task: Translate the following English text to Chinese.\n",
    "\n",
    "English text: {source}\n",
    "\n",
    "Chinese translation:\"\"\".strip()\n",
    "\n",
    "get_results_batched(\n",
    "    examples=lang_pairs[\"eng-zho\"].select(range(len(lang_pairs[\"eng-zho\"]))),\n",
    "    source_field=source_field,\n",
    "    target_field=target_field,\n",
    "    prompt_template=prompt_en2zh,\n",
    "    direction=\"eng-zho\",\n",
    "    results_list=results_to_zho\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf3f8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              source  \\\n",
      "0  周一，斯坦福大学医学院的科学家宣布，他们发明了一种可以将细胞按类型分类的新型诊断工具：一种可...   \n",
      "1  主要研究人员表示，这可以让低收入国家/地区的患者尽早发现癌症、肺结核、艾滋病和疟疾。在这些国...   \n",
      "2  当地时间上午 9:30 左右 (UTC 0230)，JAS 39C 鹰狮战斗机撞上跑道并发生...   \n",
      "3            涉事飞行员是空军中队长迪罗里·帕塔维 (Dilokrit Pattavee)。   \n",
      "4                           当地媒体报道，一辆机场消防车在响应火警时翻了车。   \n",
      "\n",
      "                                           reference strategy  \\\n",
      "0  On Monday, scientists from the Stanford Univer...   greedy   \n",
      "1  Lead researchers say this may bring early dete...   greedy   \n",
      "2  The JAS 39C Gripen crashed onto a runway at ar...   greedy   \n",
      "3  The pilot was identified as Squadron Leader Di...   greedy   \n",
      "4  Local media reports an airport fire vehicle ro...   greedy   \n",
      "\n",
      "                                         translation  total_log_probs  \\\n",
      "0  On Monday, the Stanford University Medical Sch...       -29.218750   \n",
      "1  The main researchers said that this would allo...       -39.781250   \n",
      "2  At approximately 9:30 a.m. local time (0230 UT...       -21.875000   \n",
      "3  The pilot involved was the captain of the FAA'...       -12.835938   \n",
      "4  The local media reported that a car was involv...        -9.664062   \n",
      "\n",
      "   perplexity       bleu    meteor  comet_ref  comet_wmt22  \n",
      "0    1.914211  16.997354  0.487869   0.852926     0.830248  \n",
      "1    2.118249  10.678968  0.557128   0.813916     0.762701  \n",
      "2    1.535601  20.470426  0.678425   0.857169     0.849856  \n",
      "3    2.230545   7.347053  0.192308   0.564207     0.662468  \n",
      "4    1.765571   3.458592  0.412186   0.735420     0.659111  \n",
      "---------------\n",
      "                                              source  \\\n",
      "0  On Monday, scientists from the Stanford Univer...   \n",
      "1  Lead researchers say this may bring early dete...   \n",
      "2  The JAS 39C Gripen crashed onto a runway at ar...   \n",
      "3  The pilot was identified as Squadron Leader Di...   \n",
      "4  Local media reports an airport fire vehicle ro...   \n",
      "\n",
      "                                           reference strategy  \\\n",
      "0  周一，斯坦福大学医学院的科学家宣布，他们发明了一种可以将细胞按类型分类的新型诊断工具：一种可...   greedy   \n",
      "1  主要研究人员表示，这可以让低收入国家/地区的患者尽早发现癌症、肺结核、艾滋病和疟疾。在这些国...   greedy   \n",
      "2  当地时间上午 9:30 左右 (UTC 0230)，JAS 39C 鹰狮战斗机撞上跑道并发生...   greedy   \n",
      "3            涉事飞行员是空军中队长迪罗里·帕塔维 (Dilokrit Pattavee)。   greedy   \n",
      "4                           当地媒体报道，一辆机场消防车在响应火警时翻了车。   greedy   \n",
      "\n",
      "                                         translation  total_log_probs  \\\n",
      "0  周一，斯坦福大学医学院的科学家宣布，他们发明了一种新型诊断工具，可以将细胞分类，并打印出大约...       -25.781250   \n",
      "1  研究人員說，此舉將有助於早期發現癌症、肺結核、艾滋病和疟疾，這些疾病在貧窮國家生存率可能比富...       -25.343750   \n",
      "2            飛機墜毀於機場跑道上約9時30分（0230 UTC），並造成機場暫停商業航班。       -21.921875   \n",
      "3       駕駛員的身份確認為 Squadron Leader Dilokrit Pattavee。        -4.039062   \n",
      "4                             當地媒體報導一架機場消防車在緊急出勤時翻覆。        -7.500000   \n",
      "\n",
      "   perplexity      bleu    meteor  comet_ref  comet_wmt22  \n",
      "0    2.184201  0.000000  0.000000   0.706504     0.584212  \n",
      "1    2.107293  0.000000  0.000000   0.867164     0.830613  \n",
      "2    2.252231  0.000000  0.000000   0.782798     0.760576  \n",
      "3    1.251562  8.745825  0.084746   0.723674     0.834698  \n",
      "4    1.554535  0.000000  0.000000   0.875903     0.861510  \n"
     ]
    }
   ],
   "source": [
    "# Store in CSV\n",
    "results_to_eng_df = pd.DataFrame(results_to_eng)\n",
    "results_to_zho_df = pd.DataFrame(results_to_zho)\n",
    "results_to_eng_df.to_csv(os.path.join(output_dir, \"zho-eng_bloomz-560_flores200_results.csv\"), index=False)\n",
    "results_to_zho_df.to_csv(os.path.join(output_dir, \"eng-zho_bloomz-560_flores200_results.csv\"), index=False)\n",
    "print(results_to_eng_df.head())\n",
    "print(\"---------------\")\n",
    "print(results_to_zho_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9002872e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Strategy: greedy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating (greedy): 100%|██████████| 997/997 [17:57<00:00,  1.08s/it]\n",
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Predicting DataLoader 0: 100%|██████████| 63/63 [00:12<00:00,  5.19it/s]\n",
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Predicting DataLoader 0: 100%|██████████| 63/63 [00:08<00:00,  7.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Strategy: greedy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating (greedy): 100%|██████████| 997/997 [18:52<00:00,  1.14s/it]\n",
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Predicting DataLoader 0: 100%|██████████| 63/63 [00:12<00:00,  4.95it/s]\n",
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Predicting DataLoader 0: 100%|██████████| 63/63 [00:07<00:00,  7.95it/s]\n"
     ]
    }
   ],
   "source": [
    "# fra to eng\n",
    "results_to_eng = []\n",
    "source_field = \"sentence_fra_Latn\"\n",
    "target_field = \"sentence_eng_Latn\"\n",
    "prompt_fr2en = \"\"\"Task: Translate the following French text to English.\n",
    "\n",
    "French text: {source}\n",
    "\n",
    "English translation:\"\"\".strip()\n",
    "\n",
    "get_results_batched(\n",
    "    examples=lang_pairs[\"fra-eng\"].select(range(len(lang_pairs[\"fra-eng\"]))),\n",
    "    source_field=source_field,\n",
    "    target_field=target_field,\n",
    "    prompt_template=prompt_fr2en,\n",
    "    direction=\"fra-eng\",\n",
    "    results_list=results_to_eng\n",
    ")\n",
    "\n",
    "# eng to fra\n",
    "results_to_fra = []\n",
    "source_field = \"sentence_eng_Latn\"\n",
    "target_field = \"sentence_fra_Latn\"\n",
    "prompt_en2fr = \"\"\"Task: Translate the following English text to French.\n",
    "\n",
    "English text: {source}\n",
    "\n",
    "French translation:\"\"\".strip()\n",
    "\n",
    "get_results_batched(\n",
    "    examples=lang_pairs[\"eng-fra\"].select(range(len(lang_pairs[\"eng-fra\"]))),\n",
    "    source_field=source_field,\n",
    "    target_field=target_field,\n",
    "    prompt_template=prompt_en2fr,\n",
    "    direction=\"eng-fra\",\n",
    "    results_list=results_to_fra\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fc0ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              source  \\\n",
      "0  Des scientifiques de l’école de médecine de l’...   \n",
      "1  Selon les chercheurs principaux, cela pourrait...   \n",
      "2  Le JAS 39C Gripen s’est écrasé sur une piste a...   \n",
      "3  Le pilote a été identifié comme étant le chef ...   \n",
      "4  La presse locale a rapporté qu'un véhicule de ...   \n",
      "\n",
      "                                           reference strategy  \\\n",
      "0  On Monday, scientists from the Stanford Univer...   greedy   \n",
      "1  Lead researchers say this may bring early dete...   greedy   \n",
      "2  The JAS 39C Gripen crashed onto a runway at ar...   greedy   \n",
      "3  The pilot was identified as Squadron Leader Di...   greedy   \n",
      "4  Local media reports an airport fire vehicle ro...   greedy   \n",
      "\n",
      "                                         translation  total_log_probs  \\\n",
      "0  A Stanford University medical school professor...       -43.625000   \n",
      "1  According to the main researchers, this could ...       -19.953125   \n",
      "2  The JAS 39C Gripen crashed into a runway aroun...       -12.710938   \n",
      "3     The pilot was identified as Dilokrit Pattavee.        -1.681641   \n",
      "4  Local media reported a fire vehicle was involv...       -11.750000   \n",
      "\n",
      "   perplexity       bleu    meteor  comet_ref  comet_wmt22  \n",
      "0    1.998627  12.355418  0.436580   0.806446     0.819680  \n",
      "1    1.528879  26.107435  0.554617   0.843911     0.837759  \n",
      "2    1.374065  44.783155  0.828624   0.899058     0.864757  \n",
      "3    1.127629  53.849524  0.809949   0.875813     0.717565  \n",
      "4    2.084179   8.225965  0.516011   0.777171     0.635762  \n",
      "---------------\n",
      "                                              source  \\\n",
      "0  On Monday, scientists from the Stanford Univer...   \n",
      "1  Lead researchers say this may bring early dete...   \n",
      "2  The JAS 39C Gripen crashed onto a runway at ar...   \n",
      "3  The pilot was identified as Squadron Leader Di...   \n",
      "4  Local media reports an airport fire vehicle ro...   \n",
      "\n",
      "                                           reference strategy  \\\n",
      "0  Des scientifiques de l’école de médecine de l’...   greedy   \n",
      "1  Selon les chercheurs principaux, cela pourrait...   greedy   \n",
      "2  Le JAS 39C Gripen s’est écrasé sur une piste a...   greedy   \n",
      "3  Le pilote a été identifié comme étant le chef ...   greedy   \n",
      "4  La presse locale a rapporté qu'un véhicule de ...   greedy   \n",
      "\n",
      "                                         translation  total_log_probs  \\\n",
      "0  Le lundi, les scientifiques de l'université de...       -54.250000   \n",
      "1  Les chercheurs disent que cette découverte pou...       -25.359375   \n",
      "2  Le JAS 39C Gripen a explosé à 9h30 heure local...       -25.390625   \n",
      "3  Le pilote a été identifié comme le chef de la ...        -5.035156   \n",
      "4  Les médias locaux font état d'un véhicule de l...       -17.687500   \n",
      "\n",
      "   perplexity       bleu    meteor  comet_ref  comet_wmt22  \n",
      "0    2.433533   9.643536  0.347913   0.526381     0.523591  \n",
      "1    1.585785  25.906664  0.541399   0.868335     0.872766  \n",
      "2    1.804854  30.531837  0.569754   0.871697     0.846448  \n",
      "3    1.286284  48.415247  0.730767   0.859133     0.859656  \n",
      "4    2.234410   4.580143  0.229470   0.607693     0.510050  \n"
     ]
    }
   ],
   "source": [
    "# Store in CSV\n",
    "results_to_eng_df = pd.DataFrame(results_to_eng)\n",
    "results_to_fra_df = pd.DataFrame(results_to_fra)\n",
    "results_to_eng_df.to_csv(os.path.join(output_dir, \"fra-eng_bloomz-560_flores200_results.csv\"), index=False)\n",
    "results_to_fra_df.to_csv(os.path.join(output_dir, \"eng-fra_bloomz-560_flores200_results.csv\"), index=False)\n",
    "print(results_to_eng_df.head())\n",
    "print(\"---------------\")\n",
    "print(results_to_fra_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b591e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Strategy: greedy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating (greedy): 100%|██████████| 997/997 [20:13<00:00,  1.22s/it]\n",
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Predicting DataLoader 0: 100%|██████████| 63/63 [00:14<00:00,  4.42it/s]\n",
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Predicting DataLoader 0: 100%|██████████| 63/63 [00:09<00:00,  6.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Strategy: greedy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating (greedy): 100%|██████████| 997/997 [17:32<00:00,  1.06s/it]\n",
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Predicting DataLoader 0: 100%|██████████| 63/63 [00:11<00:00,  5.25it/s]\n",
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Predicting DataLoader 0: 100%|██████████| 63/63 [00:07<00:00,  8.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# nld to eng\n",
    "results_to_eng = []\n",
    "source_field = \"sentence_nld_Latn\"\n",
    "target_field = \"sentence_eng_Latn\"\n",
    "prompt_nl2en = \"\"\"Task: Translate the following Dutch text to English.\n",
    "\n",
    "Dutch text: {source}\n",
    "\n",
    "English translation:\"\"\".strip()\n",
    "\n",
    "get_results_batched(\n",
    "    examples=lang_pairs[\"nld-eng\"].select(range(len(lang_pairs[\"nld-eng\"]))),\n",
    "    source_field=source_field,\n",
    "    target_field=target_field,\n",
    "    prompt_template=prompt_nl2en,\n",
    "    direction=\"nld-eng\",\n",
    "    results_list=results_to_eng\n",
    ")\n",
    "\n",
    "# eng to nld\n",
    "results_to_nld = []\n",
    "source_field = \"sentence_eng_Latn\"\n",
    "target_field = \"sentence_nld_Latn\"\n",
    "prompt_en2nl = \"\"\"Task: Translate the following English text to Dutch.\n",
    "\n",
    "English text: {source}\n",
    "\n",
    "Dutch translation:\"\"\".strip()\n",
    "\n",
    "get_results_batched(\n",
    "    examples=lang_pairs[\"eng-nld\"].select(range(len(lang_pairs[\"eng-nld\"]))),\n",
    "    source_field=source_field,\n",
    "    target_field=target_field,\n",
    "    prompt_template=prompt_en2nl,\n",
    "    direction=\"eng-nld\",\n",
    "    results_list=results_to_nld\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692a8f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              source  \\\n",
      "0  Op maandag kondigden wetenschappers van de Sta...   \n",
      "1  Hoofdonderzoekers zeggen dat dit kan leiden to...   \n",
      "2  De JAS 39C Gripen stortte rond 09.30 uur lokal...   \n",
      "3  De piloot werd geïdentificeerd als majoor Dilo...   \n",
      "4  De lokale media meldt dat er tijdens een actie...   \n",
      "\n",
      "                                           reference strategy  \\\n",
      "0  On Monday, scientists from the Stanford Univer...   greedy   \n",
      "1  Lead researchers say this may bring early dete...   greedy   \n",
      "2  The JAS 39C Gripen crashed onto a runway at ar...   greedy   \n",
      "3  The pilot was identified as Squadron Leader Di...   greedy   \n",
      "4  Local media reports an airport fire vehicle ro...   greedy   \n",
      "\n",
      "                                         translation  total_log_probs  \\\n",
      "0  The following Dutch text is translated: Dutch:...       -23.421875   \n",
      "1  Dutch: The Dutch language is a language of the...       -46.250000   \n",
      "2  The Dutch word for the round 9.30 pm (02.30 UT...       -34.156250   \n",
      "3  The Dutch word for \"goose\" means \"goose in the...       -19.781250   \n",
      "4  The Dutch text is: The media has been reportin...       -30.750000   \n",
      "\n",
      "   perplexity      bleu    meteor  comet_ref  comet_wmt22  \n",
      "0    1.497542  0.637162  0.042463   0.248450     0.339488  \n",
      "1    2.931697  1.512607  0.124378   0.349155     0.492640  \n",
      "2    3.122212  3.284508  0.194172   0.430914     0.410440  \n",
      "3    3.001038  3.125191  0.095238   0.375360     0.344002  \n",
      "4    3.421230  1.791171  0.112782   0.560608     0.467723  \n",
      "---------------\n",
      "                                              source  \\\n",
      "0  On Monday, scientists from the Stanford Univer...   \n",
      "1  Lead researchers say this may bring early dete...   \n",
      "2  The JAS 39C Gripen crashed onto a runway at ar...   \n",
      "3  The pilot was identified as Squadron Leader Di...   \n",
      "4  Local media reports an airport fire vehicle ro...   \n",
      "\n",
      "                                           reference strategy  \\\n",
      "0  Op maandag kondigden wetenschappers van de Sta...   greedy   \n",
      "1  Hoofdonderzoekers zeggen dat dit kan leiden to...   greedy   \n",
      "2  De JAS 39C Gripen stortte rond 09.30 uur lokal...   greedy   \n",
      "3  De piloot werd geïdentificeerd als majoor Dilo...   greedy   \n",
      "4  De lokale media meldt dat er tijdens een actie...   greedy   \n",
      "\n",
      "                                         translation  total_log_probs  \\\n",
      "0  On Monday, scientists from the Stanford Univer...        -3.269531   \n",
      "1  Dutch: Leaders say this may bring early detect...        -9.335938   \n",
      "2  The JAS 39C Gripen crashed onto a runway at ar...        -3.007812   \n",
      "3  The pilot was identified as Squadron Leader Di...        -0.466553   \n",
      "4  Local media reports a fire vehicle rolled over...        -4.738281   \n",
      "\n",
      "   perplexity       bleu    meteor  comet_ref  comet_wmt22  \n",
      "0    1.064894   8.073097  0.141329   0.668185     0.235736  \n",
      "1    1.219739   2.356906  0.073171   0.688031     0.197725  \n",
      "2    1.089738   6.321019  0.212985   0.721480     0.324312  \n",
      "3    1.027824  15.619700  0.323565   0.723221     0.341944  \n",
      "4    1.484172   2.583112  0.060976   0.548417     0.237435  \n"
     ]
    }
   ],
   "source": [
    "# Store in CSV\n",
    "results_to_eng_df = pd.DataFrame(results_to_eng)\n",
    "results_to_nld_df = pd.DataFrame(results_to_nld)\n",
    "results_to_eng_df.to_csv(os.path.join(output_dir, \"nld-eng_bloomz-560_flores200_results.csv\"), index=False)\n",
    "results_to_nld_df.to_csv(os.path.join(output_dir, \"eng-nld_bloomz-560_flores200_results.csv\"), index=False)\n",
    "print(results_to_eng_df.head())\n",
    "print(\"---------------\")\n",
    "print(results_to_nld_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26c96cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Strategy: greedy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating (greedy): 100%|██████████| 997/997 [23:31<00:00,  1.42s/it]\n",
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Predicting DataLoader 0: 100%|██████████| 63/63 [00:17<00:00,  3.70it/s]\n",
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Predicting DataLoader 0: 100%|██████████| 63/63 [00:11<00:00,  5.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# khk to eng\n",
    "results_to_eng = []\n",
    "source_field = \"sentence_khk_Cyrl\"\n",
    "target_field = \"sentence_eng_Latn\"\n",
    "prompt_kh2en = \"\"\"Task: Translate the following Mongolian text to English.\n",
    "\n",
    "Mongolian text: {source}\n",
    "\n",
    "English translation:\"\"\".strip()\n",
    "\n",
    "get_results_batched(\n",
    "    examples=lang_pairs[\"khk-eng\"].select(range(len(lang_pairs[\"khk-eng\"]))),\n",
    "    source_field=source_field,\n",
    "    target_field=target_field,\n",
    "    prompt_template=prompt_kh2en,\n",
    "    direction=\"khk-eng\",\n",
    "    results_list=results_to_eng\n",
    ")\n",
    "\n",
    "# eng to khk\n",
    "results_to_khk = []\n",
    "source_field = \"sentence_eng_Latn\"\n",
    "target_field = \"sentence_khk_Cyrl\"\n",
    "prompt_en2kh = \"\"\"Task: Translate the following English text to Mongolian.\n",
    "\n",
    "English text: {source}\n",
    "\n",
    "Mongolian translation:\"\"\".strip()\n",
    "\n",
    "get_results_batched(\n",
    "    examples=lang_pairs[\"eng-khk\"].select(range(len(lang_pairs[\"eng-khk\"]))),\n",
    "    source_field=source_field,\n",
    "    target_field=target_field,\n",
    "    prompt_template=prompt_en2kh,\n",
    "    direction=\"eng-khk\",\n",
    "    results_list=results_to_khk\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d7e68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n",
      "                                              source  \\\n",
      "0  On Monday, scientists from the Stanford Univer...   \n",
      "1  Lead researchers say this may bring early dete...   \n",
      "2  The JAS 39C Gripen crashed onto a runway at ar...   \n",
      "3  The pilot was identified as Squadron Leader Di...   \n",
      "4  Local media reports an airport fire vehicle ro...   \n",
      "\n",
      "                                           reference strategy  \\\n",
      "0  Даваа гарагт Стэнфордын Их Сургуулийн Анагаахы...   greedy   \n",
      "1  Гол судлаачдын зүгээс энэ нь хөхний хорт хавда...   greedy   \n",
      "2  ЖАС 39Си Грипен нь орон нутгийн цагаар өглөөни...   greedy   \n",
      "3  Нисгэгч нь Эскадрилийн аххлагч Дилокрит Паттав...   greedy   \n",
      "4  Нисэх онгоцны буудлын галын машин өнхөрсөн тал...   greedy   \n",
      "\n",
      "                                         translation  total_log_probs  \\\n",
      "0  Monday, scientists from the Stanford Universit...        -5.242188   \n",
      "1  Researchers say this may bring early detection...        -7.347656   \n",
      "2  JAS 39C Gripen crashed: The JAS 39C Gripen cra...       -10.828125   \n",
      "3  The pilot was identified as Squadron Leader Di...        -3.101562   \n",
      "4  Local media reports an airport fire vehicle ro...        -3.181641   \n",
      "\n",
      "   perplexity      bleu    meteor  comet_ref  comet_wmt22  \n",
      "0    1.108256  1.000940  0.024155   0.339274     0.232833  \n",
      "1    1.177368  1.091989  0.034483   0.365076     0.203936  \n",
      "2    1.286360  1.717619  0.075758   0.401102     0.257204  \n",
      "3    1.200148  4.196115  0.054945   0.399299     0.341944  \n",
      "4    1.277291  3.386499  0.041667   0.316192     0.242733  \n"
     ]
    }
   ],
   "source": [
    "# Store in CSV\n",
    "results_to_eng_df = pd.DataFrame(results_to_eng)\n",
    "results_to_khk_df = pd.DataFrame(results_to_khk)\n",
    "results_to_eng_df.to_csv(os.path.join(output_dir, \"khk-eng_bloomz-560_flores200_results.csv\"), index=False)\n",
    "results_to_khk_df.to_csv(os.path.join(output_dir, \"eng-khk_bloomz-560_flores200_results.csv\"), index=False)\n",
    "print(results_to_eng_df.head())\n",
    "print(\"---------------\")\n",
    "print(results_to_khk_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

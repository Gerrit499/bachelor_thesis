{
  "best_global_step": 220,
  "best_metric": 1.3586169481277466,
  "best_model_checkpoint": "./finetuned_lora_model_zhoeng_low\\checkpoint-220",
  "epoch": 0.9734513274336283,
  "eval_steps": 20,
  "global_step": 220,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.022123893805309734,
      "grad_norm": 2.4702260494232178,
      "learning_rate": 6.956521739130436e-05,
      "loss": 3.2795,
      "step": 5
    },
    {
      "epoch": 0.04424778761061947,
      "grad_norm": 2.825610876083374,
      "learning_rate": 0.0001565217391304348,
      "loss": 2.7407,
      "step": 10
    },
    {
      "epoch": 0.06637168141592921,
      "grad_norm": 2.120249032974243,
      "learning_rate": 0.00024347826086956525,
      "loss": 1.9993,
      "step": 15
    },
    {
      "epoch": 0.08849557522123894,
      "grad_norm": 2.3187267780303955,
      "learning_rate": 0.0003304347826086957,
      "loss": 1.7245,
      "step": 20
    },
    {
      "epoch": 0.08849557522123894,
      "eval_loss": 1.6415055990219116,
      "eval_runtime": 8.0969,
      "eval_samples_per_second": 24.824,
      "eval_steps_per_second": 6.299,
      "step": 20
    },
    {
      "epoch": 0.11061946902654868,
      "grad_norm": 1.5325778722763062,
      "learning_rate": 0.00039802955665024634,
      "loss": 1.6158,
      "step": 25
    },
    {
      "epoch": 0.13274336283185842,
      "grad_norm": 3.62286114692688,
      "learning_rate": 0.00038817733990147786,
      "loss": 1.5234,
      "step": 30
    },
    {
      "epoch": 0.15486725663716813,
      "grad_norm": 1.4474588632583618,
      "learning_rate": 0.0003783251231527094,
      "loss": 1.4585,
      "step": 35
    },
    {
      "epoch": 0.17699115044247787,
      "grad_norm": 1.4552114009857178,
      "learning_rate": 0.0003684729064039409,
      "loss": 1.4695,
      "step": 40
    },
    {
      "epoch": 0.17699115044247787,
      "eval_loss": 1.455521821975708,
      "eval_runtime": 8.0573,
      "eval_samples_per_second": 24.946,
      "eval_steps_per_second": 6.33,
      "step": 40
    },
    {
      "epoch": 0.19911504424778761,
      "grad_norm": 1.7695629596710205,
      "learning_rate": 0.0003586206896551724,
      "loss": 1.4391,
      "step": 45
    },
    {
      "epoch": 0.22123893805309736,
      "grad_norm": 1.2491528987884521,
      "learning_rate": 0.000348768472906404,
      "loss": 1.4051,
      "step": 50
    },
    {
      "epoch": 0.24336283185840707,
      "grad_norm": 1.2744439840316772,
      "learning_rate": 0.00033891625615763545,
      "loss": 1.2786,
      "step": 55
    },
    {
      "epoch": 0.26548672566371684,
      "grad_norm": 1.2778855562210083,
      "learning_rate": 0.000329064039408867,
      "loss": 1.3919,
      "step": 60
    },
    {
      "epoch": 0.26548672566371684,
      "eval_loss": 1.4259755611419678,
      "eval_runtime": 7.9355,
      "eval_samples_per_second": 25.329,
      "eval_steps_per_second": 6.427,
      "step": 60
    },
    {
      "epoch": 0.28761061946902655,
      "grad_norm": 1.2080824375152588,
      "learning_rate": 0.00031921182266009853,
      "loss": 1.5287,
      "step": 65
    },
    {
      "epoch": 0.30973451327433627,
      "grad_norm": 1.1445156335830688,
      "learning_rate": 0.0003093596059113301,
      "loss": 1.4132,
      "step": 70
    },
    {
      "epoch": 0.33185840707964603,
      "grad_norm": 1.2362885475158691,
      "learning_rate": 0.00029950738916256157,
      "loss": 1.4669,
      "step": 75
    },
    {
      "epoch": 0.35398230088495575,
      "grad_norm": 1.1941313743591309,
      "learning_rate": 0.00028965517241379314,
      "loss": 1.3831,
      "step": 80
    },
    {
      "epoch": 0.35398230088495575,
      "eval_loss": 1.4034472703933716,
      "eval_runtime": 8.4014,
      "eval_samples_per_second": 23.924,
      "eval_steps_per_second": 6.07,
      "step": 80
    },
    {
      "epoch": 0.37610619469026546,
      "grad_norm": 1.131137490272522,
      "learning_rate": 0.00027980295566502466,
      "loss": 1.3386,
      "step": 85
    },
    {
      "epoch": 0.39823008849557523,
      "grad_norm": 1.2162847518920898,
      "learning_rate": 0.0002699507389162562,
      "loss": 1.3962,
      "step": 90
    },
    {
      "epoch": 0.42035398230088494,
      "grad_norm": 1.0808897018432617,
      "learning_rate": 0.0002600985221674877,
      "loss": 1.4436,
      "step": 95
    },
    {
      "epoch": 0.4424778761061947,
      "grad_norm": 1.1786575317382812,
      "learning_rate": 0.0002502463054187192,
      "loss": 1.3958,
      "step": 100
    },
    {
      "epoch": 0.4424778761061947,
      "eval_loss": 1.3989980220794678,
      "eval_runtime": 7.9822,
      "eval_samples_per_second": 25.181,
      "eval_steps_per_second": 6.389,
      "step": 100
    },
    {
      "epoch": 0.4646017699115044,
      "grad_norm": 1.0831035375595093,
      "learning_rate": 0.00024039408866995078,
      "loss": 1.3728,
      "step": 105
    },
    {
      "epoch": 0.48672566371681414,
      "grad_norm": 1.2030081748962402,
      "learning_rate": 0.00023054187192118227,
      "loss": 1.3165,
      "step": 110
    },
    {
      "epoch": 0.5088495575221239,
      "grad_norm": 1.1548486948013306,
      "learning_rate": 0.0002206896551724138,
      "loss": 1.3806,
      "step": 115
    },
    {
      "epoch": 0.5309734513274337,
      "grad_norm": 1.1918498277664185,
      "learning_rate": 0.00021083743842364533,
      "loss": 1.3954,
      "step": 120
    },
    {
      "epoch": 0.5309734513274337,
      "eval_loss": 1.3831747770309448,
      "eval_runtime": 8.1597,
      "eval_samples_per_second": 24.633,
      "eval_steps_per_second": 6.25,
      "step": 120
    },
    {
      "epoch": 0.5530973451327433,
      "grad_norm": 1.188663363456726,
      "learning_rate": 0.00020098522167487687,
      "loss": 1.3585,
      "step": 125
    },
    {
      "epoch": 0.5752212389380531,
      "grad_norm": 1.376274824142456,
      "learning_rate": 0.0001911330049261084,
      "loss": 1.3881,
      "step": 130
    },
    {
      "epoch": 0.5973451327433629,
      "grad_norm": 1.0540051460266113,
      "learning_rate": 0.0001812807881773399,
      "loss": 1.2492,
      "step": 135
    },
    {
      "epoch": 0.6194690265486725,
      "grad_norm": 1.1659029722213745,
      "learning_rate": 0.00017142857142857143,
      "loss": 1.4243,
      "step": 140
    },
    {
      "epoch": 0.6194690265486725,
      "eval_loss": 1.3774495124816895,
      "eval_runtime": 8.0712,
      "eval_samples_per_second": 24.903,
      "eval_steps_per_second": 6.319,
      "step": 140
    },
    {
      "epoch": 0.6415929203539823,
      "grad_norm": 1.3758234977722168,
      "learning_rate": 0.00016157635467980297,
      "loss": 1.3818,
      "step": 145
    },
    {
      "epoch": 0.6637168141592921,
      "grad_norm": 1.1185320615768433,
      "learning_rate": 0.00015172413793103449,
      "loss": 1.4563,
      "step": 150
    },
    {
      "epoch": 0.6858407079646017,
      "grad_norm": 1.157959222793579,
      "learning_rate": 0.00014187192118226603,
      "loss": 1.3063,
      "step": 155
    },
    {
      "epoch": 0.7079646017699115,
      "grad_norm": 1.2547348737716675,
      "learning_rate": 0.00013201970443349755,
      "loss": 1.3644,
      "step": 160
    },
    {
      "epoch": 0.7079646017699115,
      "eval_loss": 1.3707102537155151,
      "eval_runtime": 8.2101,
      "eval_samples_per_second": 24.482,
      "eval_steps_per_second": 6.212,
      "step": 160
    },
    {
      "epoch": 0.7300884955752213,
      "grad_norm": 1.1318554878234863,
      "learning_rate": 0.00012216748768472906,
      "loss": 1.2567,
      "step": 165
    },
    {
      "epoch": 0.7522123893805309,
      "grad_norm": 1.0533175468444824,
      "learning_rate": 0.0001123152709359606,
      "loss": 1.2608,
      "step": 170
    },
    {
      "epoch": 0.7743362831858407,
      "grad_norm": 1.2003695964813232,
      "learning_rate": 0.00010246305418719213,
      "loss": 1.397,
      "step": 175
    },
    {
      "epoch": 0.7964601769911505,
      "grad_norm": 1.3155019283294678,
      "learning_rate": 9.261083743842364e-05,
      "loss": 1.2993,
      "step": 180
    },
    {
      "epoch": 0.7964601769911505,
      "eval_loss": 1.36329185962677,
      "eval_runtime": 8.2053,
      "eval_samples_per_second": 24.496,
      "eval_steps_per_second": 6.215,
      "step": 180
    },
    {
      "epoch": 0.8185840707964602,
      "grad_norm": 1.0657368898391724,
      "learning_rate": 8.275862068965517e-05,
      "loss": 1.3211,
      "step": 185
    },
    {
      "epoch": 0.8407079646017699,
      "grad_norm": 1.0990461111068726,
      "learning_rate": 7.29064039408867e-05,
      "loss": 1.2713,
      "step": 190
    },
    {
      "epoch": 0.8628318584070797,
      "grad_norm": 1.0434728860855103,
      "learning_rate": 6.305418719211823e-05,
      "loss": 1.2419,
      "step": 195
    },
    {
      "epoch": 0.8849557522123894,
      "grad_norm": 1.193691372871399,
      "learning_rate": 5.320197044334976e-05,
      "loss": 1.4918,
      "step": 200
    },
    {
      "epoch": 0.8849557522123894,
      "eval_loss": 1.360221266746521,
      "eval_runtime": 8.4954,
      "eval_samples_per_second": 23.66,
      "eval_steps_per_second": 6.003,
      "step": 200
    },
    {
      "epoch": 0.9070796460176991,
      "grad_norm": 1.1425281763076782,
      "learning_rate": 4.334975369458129e-05,
      "loss": 1.239,
      "step": 205
    },
    {
      "epoch": 0.9292035398230089,
      "grad_norm": 1.0520169734954834,
      "learning_rate": 3.3497536945812806e-05,
      "loss": 1.2477,
      "step": 210
    },
    {
      "epoch": 0.9513274336283186,
      "grad_norm": 1.1192578077316284,
      "learning_rate": 2.3645320197044336e-05,
      "loss": 1.3462,
      "step": 215
    },
    {
      "epoch": 0.9734513274336283,
      "grad_norm": 1.2187142372131348,
      "learning_rate": 1.3793103448275863e-05,
      "loss": 1.4404,
      "step": 220
    },
    {
      "epoch": 0.9734513274336283,
      "eval_loss": 1.3586169481277466,
      "eval_runtime": 8.5916,
      "eval_samples_per_second": 23.395,
      "eval_steps_per_second": 5.936,
      "step": 220
    }
  ],
  "logging_steps": 5,
  "max_steps": 226,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 20,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 825766182912000.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}

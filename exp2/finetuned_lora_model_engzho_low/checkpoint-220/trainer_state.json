{
  "best_global_step": 220,
  "best_metric": 1.800154447555542,
  "best_model_checkpoint": "./finetuned_lora_model_engzho_low\\checkpoint-220",
  "epoch": 0.9734513274336283,
  "eval_steps": 20,
  "global_step": 220,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.022123893805309734,
      "grad_norm": 4.599604606628418,
      "learning_rate": 6.956521739130436e-05,
      "loss": 4.0453,
      "step": 5
    },
    {
      "epoch": 0.04424778761061947,
      "grad_norm": 2.5827693939208984,
      "learning_rate": 0.0001565217391304348,
      "loss": 3.29,
      "step": 10
    },
    {
      "epoch": 0.06637168141592921,
      "grad_norm": 2.2198336124420166,
      "learning_rate": 0.00024347826086956525,
      "loss": 2.439,
      "step": 15
    },
    {
      "epoch": 0.08849557522123894,
      "grad_norm": 1.3724206686019897,
      "learning_rate": 0.0003304347826086957,
      "loss": 2.0607,
      "step": 20
    },
    {
      "epoch": 0.08849557522123894,
      "eval_loss": 1.9946779012680054,
      "eval_runtime": 7.3646,
      "eval_samples_per_second": 27.293,
      "eval_steps_per_second": 6.925,
      "step": 20
    },
    {
      "epoch": 0.11061946902654868,
      "grad_norm": 1.3450244665145874,
      "learning_rate": 0.00039802955665024634,
      "loss": 1.9754,
      "step": 25
    },
    {
      "epoch": 0.13274336283185842,
      "grad_norm": 1.1363314390182495,
      "learning_rate": 0.00038817733990147786,
      "loss": 1.8916,
      "step": 30
    },
    {
      "epoch": 0.15486725663716813,
      "grad_norm": 1.130368709564209,
      "learning_rate": 0.0003783251231527094,
      "loss": 2.0702,
      "step": 35
    },
    {
      "epoch": 0.17699115044247787,
      "grad_norm": 1.1336820125579834,
      "learning_rate": 0.0003684729064039409,
      "loss": 1.801,
      "step": 40
    },
    {
      "epoch": 0.17699115044247787,
      "eval_loss": 1.8720260858535767,
      "eval_runtime": 7.4678,
      "eval_samples_per_second": 26.916,
      "eval_steps_per_second": 6.829,
      "step": 40
    },
    {
      "epoch": 0.19911504424778761,
      "grad_norm": 1.223006248474121,
      "learning_rate": 0.0003586206896551724,
      "loss": 1.9579,
      "step": 45
    },
    {
      "epoch": 0.22123893805309736,
      "grad_norm": 1.3219003677368164,
      "learning_rate": 0.000348768472906404,
      "loss": 1.8995,
      "step": 50
    },
    {
      "epoch": 0.24336283185840707,
      "grad_norm": 1.1153055429458618,
      "learning_rate": 0.00033891625615763545,
      "loss": 1.7743,
      "step": 55
    },
    {
      "epoch": 0.26548672566371684,
      "grad_norm": 1.2369765043258667,
      "learning_rate": 0.000329064039408867,
      "loss": 1.8627,
      "step": 60
    },
    {
      "epoch": 0.26548672566371684,
      "eval_loss": 1.85031259059906,
      "eval_runtime": 7.5163,
      "eval_samples_per_second": 26.742,
      "eval_steps_per_second": 6.785,
      "step": 60
    },
    {
      "epoch": 0.28761061946902655,
      "grad_norm": 1.0802336931228638,
      "learning_rate": 0.00031921182266009853,
      "loss": 1.9626,
      "step": 65
    },
    {
      "epoch": 0.30973451327433627,
      "grad_norm": 1.0501041412353516,
      "learning_rate": 0.0003093596059113301,
      "loss": 1.866,
      "step": 70
    },
    {
      "epoch": 0.33185840707964603,
      "grad_norm": 1.0209883451461792,
      "learning_rate": 0.00029950738916256157,
      "loss": 1.8025,
      "step": 75
    },
    {
      "epoch": 0.35398230088495575,
      "grad_norm": 0.9984893202781677,
      "learning_rate": 0.00028965517241379314,
      "loss": 1.7931,
      "step": 80
    },
    {
      "epoch": 0.35398230088495575,
      "eval_loss": 1.844101905822754,
      "eval_runtime": 7.4635,
      "eval_samples_per_second": 26.931,
      "eval_steps_per_second": 6.833,
      "step": 80
    },
    {
      "epoch": 0.37610619469026546,
      "grad_norm": 1.0402164459228516,
      "learning_rate": 0.00027980295566502466,
      "loss": 1.8534,
      "step": 85
    },
    {
      "epoch": 0.39823008849557523,
      "grad_norm": 1.080214262008667,
      "learning_rate": 0.0002699507389162562,
      "loss": 1.7844,
      "step": 90
    },
    {
      "epoch": 0.42035398230088494,
      "grad_norm": 1.0711071491241455,
      "learning_rate": 0.0002600985221674877,
      "loss": 1.7659,
      "step": 95
    },
    {
      "epoch": 0.4424778761061947,
      "grad_norm": 1.116868257522583,
      "learning_rate": 0.0002502463054187192,
      "loss": 1.7106,
      "step": 100
    },
    {
      "epoch": 0.4424778761061947,
      "eval_loss": 1.828398585319519,
      "eval_runtime": 7.4747,
      "eval_samples_per_second": 26.891,
      "eval_steps_per_second": 6.823,
      "step": 100
    },
    {
      "epoch": 0.4646017699115044,
      "grad_norm": 1.0900888442993164,
      "learning_rate": 0.00024039408866995078,
      "loss": 1.8285,
      "step": 105
    },
    {
      "epoch": 0.48672566371681414,
      "grad_norm": 1.201351284980774,
      "learning_rate": 0.00023054187192118227,
      "loss": 1.8061,
      "step": 110
    },
    {
      "epoch": 0.5088495575221239,
      "grad_norm": 0.9945099949836731,
      "learning_rate": 0.0002206896551724138,
      "loss": 1.8491,
      "step": 115
    },
    {
      "epoch": 0.5309734513274337,
      "grad_norm": 1.0418951511383057,
      "learning_rate": 0.00021083743842364533,
      "loss": 1.7797,
      "step": 120
    },
    {
      "epoch": 0.5309734513274337,
      "eval_loss": 1.8201826810836792,
      "eval_runtime": 7.4368,
      "eval_samples_per_second": 27.028,
      "eval_steps_per_second": 6.858,
      "step": 120
    },
    {
      "epoch": 0.5530973451327433,
      "grad_norm": 0.9867340326309204,
      "learning_rate": 0.00020098522167487687,
      "loss": 1.7673,
      "step": 125
    },
    {
      "epoch": 0.5752212389380531,
      "grad_norm": 1.2022300958633423,
      "learning_rate": 0.0001911330049261084,
      "loss": 1.9243,
      "step": 130
    },
    {
      "epoch": 0.5973451327433629,
      "grad_norm": 1.1276112794876099,
      "learning_rate": 0.0001812807881773399,
      "loss": 1.7147,
      "step": 135
    },
    {
      "epoch": 0.6194690265486725,
      "grad_norm": 1.0800461769104004,
      "learning_rate": 0.00017142857142857143,
      "loss": 1.8828,
      "step": 140
    },
    {
      "epoch": 0.6194690265486725,
      "eval_loss": 1.8134276866912842,
      "eval_runtime": 7.4475,
      "eval_samples_per_second": 26.989,
      "eval_steps_per_second": 6.848,
      "step": 140
    },
    {
      "epoch": 0.6415929203539823,
      "grad_norm": 1.0686284303665161,
      "learning_rate": 0.00016157635467980297,
      "loss": 1.8012,
      "step": 145
    },
    {
      "epoch": 0.6637168141592921,
      "grad_norm": 1.138120174407959,
      "learning_rate": 0.00015172413793103449,
      "loss": 1.7834,
      "step": 150
    },
    {
      "epoch": 0.6858407079646017,
      "grad_norm": 1.154374122619629,
      "learning_rate": 0.00014187192118226603,
      "loss": 1.8556,
      "step": 155
    },
    {
      "epoch": 0.7079646017699115,
      "grad_norm": 1.192880392074585,
      "learning_rate": 0.00013201970443349755,
      "loss": 1.8097,
      "step": 160
    },
    {
      "epoch": 0.7079646017699115,
      "eval_loss": 1.8128029108047485,
      "eval_runtime": 7.5569,
      "eval_samples_per_second": 26.598,
      "eval_steps_per_second": 6.749,
      "step": 160
    },
    {
      "epoch": 0.7300884955752213,
      "grad_norm": 1.1366771459579468,
      "learning_rate": 0.00012216748768472906,
      "loss": 1.8322,
      "step": 165
    },
    {
      "epoch": 0.7522123893805309,
      "grad_norm": 1.1109662055969238,
      "learning_rate": 0.0001123152709359606,
      "loss": 1.8293,
      "step": 170
    },
    {
      "epoch": 0.7743362831858407,
      "grad_norm": 0.9485195875167847,
      "learning_rate": 0.00010246305418719213,
      "loss": 1.7491,
      "step": 175
    },
    {
      "epoch": 0.7964601769911505,
      "grad_norm": 1.0974677801132202,
      "learning_rate": 9.261083743842364e-05,
      "loss": 1.6974,
      "step": 180
    },
    {
      "epoch": 0.7964601769911505,
      "eval_loss": 1.8059276342391968,
      "eval_runtime": 7.5137,
      "eval_samples_per_second": 26.751,
      "eval_steps_per_second": 6.788,
      "step": 180
    },
    {
      "epoch": 0.8185840707964602,
      "grad_norm": 0.9560993313789368,
      "learning_rate": 8.275862068965517e-05,
      "loss": 1.7799,
      "step": 185
    },
    {
      "epoch": 0.8407079646017699,
      "grad_norm": 1.192735195159912,
      "learning_rate": 7.29064039408867e-05,
      "loss": 1.8537,
      "step": 190
    },
    {
      "epoch": 0.8628318584070797,
      "grad_norm": 1.1289852857589722,
      "learning_rate": 6.305418719211823e-05,
      "loss": 1.7599,
      "step": 195
    },
    {
      "epoch": 0.8849557522123894,
      "grad_norm": 1.1215729713439941,
      "learning_rate": 5.320197044334976e-05,
      "loss": 1.6112,
      "step": 200
    },
    {
      "epoch": 0.8849557522123894,
      "eval_loss": 1.8009699583053589,
      "eval_runtime": 7.6758,
      "eval_samples_per_second": 26.186,
      "eval_steps_per_second": 6.644,
      "step": 200
    },
    {
      "epoch": 0.9070796460176991,
      "grad_norm": 1.1642714738845825,
      "learning_rate": 4.334975369458129e-05,
      "loss": 1.7322,
      "step": 205
    },
    {
      "epoch": 0.9292035398230089,
      "grad_norm": 1.0233018398284912,
      "learning_rate": 3.3497536945812806e-05,
      "loss": 1.6802,
      "step": 210
    },
    {
      "epoch": 0.9513274336283186,
      "grad_norm": 1.0993916988372803,
      "learning_rate": 2.3645320197044336e-05,
      "loss": 1.7547,
      "step": 215
    },
    {
      "epoch": 0.9734513274336283,
      "grad_norm": 1.1407973766326904,
      "learning_rate": 1.3793103448275863e-05,
      "loss": 1.732,
      "step": 220
    },
    {
      "epoch": 0.9734513274336283,
      "eval_loss": 1.800154447555542,
      "eval_runtime": 7.6625,
      "eval_samples_per_second": 26.232,
      "eval_steps_per_second": 6.656,
      "step": 220
    }
  ],
  "logging_steps": 5,
  "max_steps": 226,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 20,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 825766182912000.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
